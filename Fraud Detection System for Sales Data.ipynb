{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97e88d84-4c79-4122-95b9-0b58b3aaf50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     37151\n",
      "         1.0       1.00      1.00      1.00      2633\n",
      "\n",
      "    accuracy                           1.00     39784\n",
      "   macro avg       1.00      1.00      1.00     39784\n",
      "weighted avg       1.00      1.00      1.00     39784\n",
      "\n",
      "Logistic Regression - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     37151\n",
      "         1.0       1.00      1.00      1.00      2633\n",
      "\n",
      "    accuracy                           1.00     39784\n",
      "   macro avg       1.00      1.00      1.00     39784\n",
      "weighted avg       1.00      1.00      1.00     39784\n",
      "\n",
      "Gradient Boosting - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     37151\n",
      "         1.0       1.00      1.00      1.00      2633\n",
      "\n",
      "    accuracy                           1.00     39784\n",
      "   macro avg       1.00      1.00      1.00     39784\n",
      "weighted avg       1.00      1.00      1.00     39784\n",
      "\n",
      "Random Forest - Confusion Matrix:\n",
      "[[37151     0]\n",
      " [    0  2633]]\n",
      "Random Forest Cross-Validation Score:\n",
      "1.0\n",
      "Logistic Regression Cross-Validation Score:\n",
      "0.9999966391073469\n",
      "Gradient Boosting Cross-Validation Score:\n",
      "1.0\n",
      "Random Forest - Feature Importances:\n",
      "MarketingType: 0.0021131255599540605\n",
      "PriceReg: 0.0029242371717792255\n",
      "LowUserPrice: 0.0029449772580096133\n",
      "New_Release_Flag: 0.00522317230975387\n",
      "StrengthFactor: 0.005334987956624356\n",
      "LowNetPrice: 0.007409421846551218\n",
      "SoldCount: 0.014047158247126997\n",
      "ReleaseYear: 0.03018747336623316\n",
      "ItemCount: 0.11526678761990271\n",
      "File_Type: 0.8145486586640649\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE  # For handling imbalanced datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'A://SalesKaggle3.csv'  # Update the file path if needed\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Preprocess the data\n",
    "data.fillna(0, inplace=True)\n",
    "\n",
    "# Assuming 'SoldFlag' is the target column (1 = fraud, 0 = non-fraud)\n",
    "target = 'SoldFlag'  # Modify if necessary\n",
    "features = data.drop(columns=[target, 'Order', 'SKU_number', 'ReleaseNumber'])\n",
    "\n",
    "# Encoding categorical features\n",
    "label_encoder = LabelEncoder()\n",
    "features['MarketingType'] = label_encoder.fit_transform(features['MarketingType'])\n",
    "features['New_Release_Flag'] = label_encoder.fit_transform(features['New_Release_Flag'])\n",
    "\n",
    "# Feature engineering: Price variance between regular price and low user price\n",
    "features['Price_Variance'] = features['PriceReg'] - features['LowUserPrice']\n",
    "\n",
    "# Optional: Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features.select_dtypes(include=[np.number]))\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, data[target], test_size=0.2, random_state=42)\n",
    "\n",
    "# Handle class imbalance using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Initialize classifiers\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "lr_model = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Train models\n",
    "rf_model.fit(X_train_res, y_train_res)\n",
    "lr_model.fit(X_train_res, y_train_res)\n",
    "gb_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Predict on the test set\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "gb_pred = gb_model.predict(X_test)\n",
    "\n",
    "# Evaluate models\n",
    "print(\"Random Forest - Classification Report:\")\n",
    "print(classification_report(y_test, rf_pred))\n",
    "\n",
    "print(\"Logistic Regression - Classification Report:\")\n",
    "print(classification_report(y_test, lr_pred))\n",
    "\n",
    "print(\"Gradient Boosting - Classification Report:\")\n",
    "print(classification_report(y_test, gb_pred))\n",
    "\n",
    "print(\"Random Forest - Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, rf_pred))\n",
    "\n",
    "# Model Comparison: Cross-validation scores\n",
    "print(\"Random Forest Cross-Validation Score:\")\n",
    "print(np.mean(cross_val_score(rf_model, X_train_res, y_train_res, cv=5)))\n",
    "\n",
    "print(\"Logistic Regression Cross-Validation Score:\")\n",
    "print(np.mean(cross_val_score(lr_model, X_train_res, y_train_res, cv=5)))\n",
    "\n",
    "print(\"Gradient Boosting Cross-Validation Score:\")\n",
    "print(np.mean(cross_val_score(gb_model, X_train_res, y_train_res, cv=5)))\n",
    "\n",
    "# Feature importance (optional, to understand which features matter most for Random Forest)\n",
    "importances = rf_model.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "print(\"Random Forest - Feature Importances:\")\n",
    "for i in indices:\n",
    "    print(f\"{features.columns[i]}: {importances[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7be49fb-f0e1-4d02-9f91-262531927830",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
